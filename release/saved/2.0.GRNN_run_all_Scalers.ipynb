{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler, Normalizer, PowerTransformer, RobustScaler, StandardScaler, PolynomialFeatures\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from scipy.optimize import differential_evolution\n",
        "from sklearn.metrics import max_error, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, median_absolute_error, r2_score\n",
        "import time\n",
        "\n",
        "\n",
        "scalers = {\n",
        "    \"PolynomialFeatures\" : PolynomialFeatures\n",
        "    # \"MaxAbsScaler\"     : MaxAbsScaler,\n",
        "    # \"MinMaxScaler\"     : MinMaxScaler,\n",
        "    # \"Normalizer\"       : Normalizer,\n",
        "    # \"PowerTransformer\" : PowerTransformer,\n",
        "    # \"RobustScaler\"     : RobustScaler,\n",
        "    # \"StandardScaler\"   : StandardScaler\n",
        "}\n",
        "\n",
        "class GRNN(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, name = \"GRNN\", sigma = 0.1):\n",
        "        self.name = name\n",
        "        self.sigma = 2 * np.power(sigma, 2)\n",
        "\n",
        "    def predict(self, instance_X, X_train_scaled, Y_train):\n",
        "        gausian_distances = np.exp(-np.power(np.sqrt((np.square(X_train_scaled-instance_X).sum(axis=1))),2) / self.sigma)\n",
        "        gausian_distances_sum = gausian_distances.sum()\n",
        "        gausian_distances_sum = max(gausian_distances_sum, 1e-07)\n",
        "        return np.multiply(gausian_distances, Y_train).sum() / gausian_distances_sum\n",
        "\n",
        "# Load all data with pandas\n",
        "data = pd.read_csv('/content/Tunneling_Induced_building_damage_dataset.txt', sep='\\t')\n",
        "data = data.drop(labels = 'Tot No. Simulations', axis=1)\n",
        "data_columns = data.columns\n",
        "data.head()\n",
        "\n",
        "X = data.iloc[:,:15]\n",
        "Y = data.iloc[:,15:]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
        "Y_train = Y_train.to_numpy()\n",
        "Y_test = Y_test.to_numpy()\n",
        "\n",
        "\n",
        "for (name, scaler_type) in scalers.items():\n",
        "  # Transform data\n",
        "  data_scaler = scaler_type()\n",
        "  X_train = data_scaler.fit_transform(X_train)\n",
        "  X_test = data_scaler.transform(X_test)\n",
        "\n",
        "  results = {}\n",
        "  # cost function to optimize\n",
        "  def f(params, X_train, Y_train, X_test, Y_test):\n",
        "      s, = params  # Unpack the parameters\n",
        "      grnn = GRNN(sigma=s)\n",
        "      predictions = np.array([grnn.predict(i, X_train, Y_train) for i in X_test])\n",
        "      return mean_squared_error(Y_test, predictions) # USE MSE\n",
        "\n",
        "  for i in range(Y_train.shape[1]):\n",
        "      start_time = time.time()\n",
        "\n",
        "      res = differential_evolution(f, bounds=[(0.001, 10)], args=(X_train, Y_train[:, i], X_test, Y_test[:, i]))\n",
        "      s = res[\"x\"][0]\n",
        "\n",
        "      grnn = GRNN(sigma=s)\n",
        "      predictions = np.apply_along_axis(lambda x: grnn.predict(x, X_train, Y_train[:, i]), axis=1, arr=X_test)\n",
        "\n",
        "      exp_time = time.time() - start_time\n",
        "\n",
        "\n",
        "      MaxError = max_error                    (Y_test[:,i].ravel(), predictions)\n",
        "      MAE = mean_absolute_error               (Y_test[:,i].ravel(), predictions)\n",
        "      MSE = mean_squared_error                (Y_test[:,i].ravel(), predictions)\n",
        "      MedError = median_absolute_error        (Y_test[:,i].ravel(), predictions)\n",
        "      RMSE = mean_squared_error               (Y_test[:,i].ravel(), predictions, squared=False)\n",
        "      MAPE = mean_absolute_percentage_error   (Y_test[:,i].ravel(), predictions)\n",
        "      R2 = r2_score                           (Y_test[:,i].ravel(), predictions)\n",
        "\n",
        "      results.update({\n",
        "          f'test_{i+1}':\n",
        "              {\n",
        "                  'time': exp_time,\n",
        "                  'sigma': s,\n",
        "                  # 'y_true': Y_test[:,i].ravel(),\n",
        "                  # 'y_pred': predictions,\n",
        "                  'MaxError' : MaxError,\n",
        "                  'MAE' : MAE,\n",
        "                  'MSE' : MSE,\n",
        "                  'MedError' : MedError,\n",
        "                  'RMSE' : RMSE,\n",
        "                  'MAPE' : MAPE,\n",
        "                  'R2' : R2\n",
        "              }\n",
        "      })\n",
        "\n",
        "  exp_result = pd.DataFrame(results)\n",
        "  exp_result.to_excel(f'MSE_{name}.xlsx')"
      ],
      "metadata": {
        "id": "E6TZdK96jzEE"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}